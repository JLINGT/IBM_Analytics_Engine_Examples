{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "In this notebook, we use the Bluemix CLI tools to create a new IBM Analytics Engine instance that is configured to use IBM Cloud Object Storage (IBM COS).\n",
    "\n",
    "*Prerequisites:* \n",
    "- You have worked through the notebook `examples/CLI/CLI_Setup.ipynb`\n",
    "\n",
    "*Recommended:*\n",
    "- You have worked through the notebook `examples/CLI/Provision_IAE.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "## Load utility library and set notebook width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent this notebook from getting too cluttered, we use some python utilities.  We load them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../modules\")\n",
    "import iae_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set this notebook to use the full width of the browser using the utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iae_examples.set_notebook_full_width()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Read Cloud Foundry endpoint properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read some variables saved when we ran the notebook `examples/CLI/CLI_Setup.ipynb` to configure our choosen api, org and space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CF_API, CF_ORG, CF_SPACE) = iae_examples.read_cf_target_endpoint_details('../../secrets/cf_target_endpoint.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Save IBM Cloud Object Storage endpoint properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file `../../cos_s3_endpoint.json` with your COS credentials.  The file format should be:\n",
    "\n",
    "```\n",
    "{\n",
    "   \"S3_ACCESS_KEY\":       \"<AccessKey-changeme>\",\n",
    "   \"S3_PRIVATE_ENDPOINT\": \"<Private-EndPoint-changeme>\",\n",
    "   \"S3_PUBLIC_ENDPOINT\":  \"<Public-EndPoint-changeme>\",\n",
    "   \"S3_SECRET_KEY\":       \"<SecretKey-changeme>\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the cos file into some variables that we will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(S3_ACCESS_KEY, S3_PRIVATE_ENDPOINT, S3_PUBLIC_ENDPOINT, S3_SECRET_KEY) = \\\n",
    "    iae_examples.read_cos_endpoint_details('../../secrets/cos_s3_endpoint.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Provision IAE instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can provision IAE, we need to login to Bluemix using the Bluemix CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx login --apikey @../../apiKey.json -a {CF_API} -o {CF_ORG} -s {CF_SPACE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways to configure IAE to use IBM COS.   Let's automate the process with a custom script.\n",
    "\n",
    "**NOTE:** These examples prefer automation to manual approaches for configuration.  One key benefit of automation is that it supports creating environments in a repeatable and testable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "custom_script = { \n",
    "    \"num_compute_nodes\": 1, \n",
    "    \"hardware_config\": \"Standard\", \n",
    "    \"software_package\": \"ae-1.0-spark\",\n",
    "    \"customization\": [{\n",
    "        \"name\": \"action1\",\n",
    "        \"type\": \"bootstrap\",\n",
    "        \"script\": {\n",
    "            \"source_type\": \"http\",\n",
    "            \"script_path\": \"http://raw.githubusercontent.com/snowch/IBM_Analytics_Engine_Examples/master/scripts/COS_S3.sh\"\n",
    "            },\n",
    "        \"script_params\": [S3_ACCESS_KEY, S3_PRIVATE_ENDPOINT, S3_SECRET_KEY]\n",
    "        }]\n",
    "}\n",
    "\n",
    "# write the script to a file in the local directory where we can access it in the next step using the Bluemix CLI \n",
    "\n",
    "with open('custom_script.json', 'w') as f:\n",
    "    f.write(json.dumps(custom_script))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then attempt to create an IBM Analytics Engine Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf create-service IBMAnalyticsEngine Standard 'myiaeinstance' -c custom_script.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Note the output from above.  If all went ok, the CLI should suggest running `cf service myiaeinstance` to check the provisioning status. Let's do that now.\n",
    "\n",
    "**NOTE:** If there is an error output by the above step, jump to the section below on debugging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf service myiaeinstance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create service key\n",
    "\n",
    "Here we create a service key which contains the cluster credentials. \n",
    "We export the service key information to a file. \n",
    "We can then read the service key details into python variables so we can use those variables later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf create-service-key myiaeinstance myiaeinstance_servicekey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf service-keys myiaeinstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf service-key myiaeinstance myiaeinstance_servicekey > ../../iae_service_key.json\n",
    "\n",
    "# unfortunately, the output of this command contains some lines of text before the json\n",
    "# lets remove the first four lines of output and save the raw json\n",
    "\n",
    "# TODO move this to the utility module\n",
    "\n",
    "with open('../../iae_service_key.json') as data_file:\n",
    "    data = ''.join(data_file.readlines()[4:])\n",
    "    \n",
    "with open('../../iae_service_key.json', 'w') as data_file:\n",
    "    data_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO move this to the utility module\n",
    "\n",
    "import json\n",
    "\n",
    "with open('../../iae_service_key.json') as data_file:    \n",
    "    iae_service_key = json.load(data_file)\n",
    "    \n",
    "livy   = iae_service_key['cluster']['service_endpoints']['livy']\n",
    "ambari = iae_service_key['cluster']['service_endpoints']['ambari_console']\n",
    "user   = iae_service_key['cluster']['user']\n",
    "pswd   = iae_service_key['cluster']['password']\n",
    "   \n",
    "print('livy:   '   + livy)\n",
    "print('ambari: '   + ambari)\n",
    "print('user:   '   + user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Verify COS was successfully configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iae_examples.is_s3_access_key_set(ambari, user, pswd, S3_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Upload file to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto\n",
    "import boto.s3.connection\n",
    "import logging\n",
    "\n",
    "boto.set_stream_logger('paws', level=logging.ERROR)\n",
    "\n",
    "conn = boto.connect_s3(\n",
    "        aws_access_key_id = S3_ACCESS_KEY,\n",
    "        aws_secret_access_key = S3_SECRET_KEY,\n",
    "        host = S3_PUBLIC_ENDPOINT,\n",
    "        calling_format = boto.s3.connection.OrdinaryCallingFormat(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket = conn.get_bucket('temp-bucket')\n",
    "except:\n",
    "    bucket = conn.create_bucket('temp-bucket')\n",
    "    \n",
    "print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_contents = \"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "from random import random\n",
    "from operator import add\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"PythonPi\").getOrCreate()\n",
    "\n",
    "    partitions = 2\n",
    "    n = 100000 * partitions\n",
    "\n",
    "    def f(_):\n",
    "        x = random() * 2 - 1\n",
    "        y = random() * 2 - 1\n",
    "        return 1 if x ** 2 + y ** 2 <= 1 else 0\n",
    "\n",
    "    count = spark.sparkContext.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\n",
    "    print(\"Pi is roughly %f\" % (4.0 * count / n))\n",
    "\n",
    "    spark.stop()\n",
    "\"\"\"\n",
    "\n",
    "with open('PiEx.py', 'w') as pyspark_file:\n",
    "    pyspark_file.write(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = bucket.new_key('PiEx.py')\n",
    "key.set_contents_from_filename('PiEx.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analyse data with Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = { \n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Requested-By': 'livy'\n",
    "}\n",
    "data = { \"file\":\"s3a://{0}/PiEx.py\".format(bucket.name) }\n",
    "\n",
    "res = requests.post(livy, auth=(user, pswd), headers=headers, data=json.dumps(data))\n",
    "\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = { \n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Requested-By': 'livy'\n",
    "}\n",
    "res = requests.get(livy, auth=(user, pswd), headers=headers)\n",
    "\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Debugging \n",
    "\n",
    "TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf space dev --guid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf service-keys myiaeinstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf delete-service-key myiaeinstance myiaeinstance_servicekey -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! bx cf delete-service myiaeinstance -f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
